Generated from train_ney.py in Handy repository (https://github.com/pauloabelha/handy.git)
Timestamp: 2018-11-22 11:15:03
Device: cuda:0
GPU: GeForce GTX 1080 Ti
Arguments: Namespace(checkpoint_filepath='lstm_baseline.pth.tar', data_loader='fpa_dataset.FPADataLoaderObjRGBReconstruction', dataset_dict="{'root_folder': 'C:/Users/Administrator/Documents/Datasets/fpa_benchmark/', 'batch_size': 2, 'split_filename': 'fpa_split_obj_pose.p', 'img_res': (240, 135)}", log_filepath='log_net.txt', log_img_prefix='log_img_', log_interval=10, log_root_folder='', lr=1.0, max_log_images=4, momentum=0.9, net='reconstruction_net.ReconstructNet', net_dict="{'num_input_channels': 3}", num_epochs=10, weight_decay=0.005)
Network params dict: {'num_input_channels': 3}
Network loaded: 
ReconstructNet(
  (conv_sequence): Sequential(
    (0): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (3): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (4): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (5): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (6): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (7): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
  (flatten): NetBlocksFlatten()
  (deconv_sequence): Sequential(
    (0): Sequential(
      (0): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (1): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (2): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (3): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (4): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (5): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (6): Sequential(
      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
    (7): Sequential(
      (0): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1))
      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
    )
  )
)
Dataset params dict: {'root_folder': 'C:/Users/Administrator/Documents/Datasets/fpa_benchmark/', 'batch_size': 2, 'split_filename': 'fpa_split_obj_pose.p', 'img_res': (240, 135), 'type': 'train'}
Data loader loaded: <function FPADataLoaderObjRGBReconstruction at 0x0000023AF129D1E0>
Dataset length: 7525
Optimizer loaded: Adadelta (
Parameter Group 0
    eps: 1e-06
    lr: 1.0
    rho: 0.9
    weight_decay: 0.005
)
Training started
Training: Epoch 0/9, Batch 0/7524, Current loss 0.38445693254470825, Average (last 10) loss: 0.38445693254470825, Diff (avg loss) 0.38445693254470825, Log Interval 10
Training: Epoch 0/9, Batch 10/7524, Current loss 0.18367484211921692, Average (last 10) loss: 0.20037524849176408, Diff (avg loss) -0.18408168405294417, Log Interval 10
Training: Epoch 0/9, Batch 20/7524, Current loss 0.16741766035556793, Average (last 10) loss: 0.16634260565042497, Diff (avg loss) -0.03403264284133911, Log Interval 10
Training: Epoch 0/9, Batch 30/7524, Current loss 0.16152328252792358, Average (last 10) loss: 0.16273096650838853, Diff (avg loss) -0.003611639142036438, Log Interval 10
Training: Epoch 0/9, Batch 40/7524, Current loss 0.16124342381954193, Average (last 10) loss: 0.1611943930387497, Diff (avg loss) -0.0015365734696388411, Log Interval 10
Training: Epoch 0/9, Batch 50/7524, Current loss 0.16115710139274597, Average (last 10) loss: 0.15973712205886842, Diff (avg loss) -0.00145727097988127, Log Interval 10
Training: Epoch 0/9, Batch 60/7524, Current loss 0.1580069214105606, Average (last 10) loss: 0.15943171381950377, Diff (avg loss) -0.00030540823936464623, Log Interval 10
Training: Epoch 0/9, Batch 70/7524, Current loss 0.1576385796070099, Average (last 10) loss: 0.15901750028133393, Diff (avg loss) -0.00041421353816983864, Log Interval 10
Training: Epoch 0/9, Batch 80/7524, Current loss 0.15998996794223785, Average (last 10) loss: 0.15905135422945021, Diff (avg loss) 3.3853948116280286e-05, Log Interval 10
Training: Epoch 0/9, Batch 90/7524, Current loss 0.15714512765407562, Average (last 10) loss: 0.15878646671772004, Diff (avg loss) -0.00026488751173017744, Log Interval 10
Training: Epoch 0/9, Batch 100/7524, Current loss 0.15575316548347473, Average (last 10) loss: 0.15619215220212937, Diff (avg loss) -0.0025943145155906677, Log Interval 10
